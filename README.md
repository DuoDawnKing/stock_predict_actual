The two programs uploaded are predicted versus actual when using a deep learning tool. for this example we will be using bitcoin sentiment and bitcoin history of the closing for the model. we joined the data to one dataframe then we set up a window day for the closing prices and see how it affects the model. The difference between both codes is one has a feature column index set to 1 and the other to 0
we split the train data uses 70 percent and the test data uses the remainder of the data. We then scaled the train adn test so that we can reshape for the model. from there we set up the model an set it with 3 layers and an output. We then fit the train model into it.
After the train was fit into it. we would predict the test then do inverse transofrm of the predicted and y test from there we put them into a new dataframe that is separated by real and predicted. we graph the models to show the difference
the closing model plot is somewhat close where the predicted model showed similar reaction to that of real plot line but it didnt mirror. However for the fear index(index column of 0) the predicted plot graph was completly different from the others which shows a data issue, meaning we were predicting too high at the beginning and then too low at the end. could be improved from changing the amount of data we used for the prediciton 
